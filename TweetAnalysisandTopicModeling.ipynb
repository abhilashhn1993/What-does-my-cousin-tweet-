{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WhatDoYouTweet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPEec6ThrgE2BKCNTDYizWS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhilashhn1993/What-does-my-cousin-tweet-/blob/master/TweetAnalysisandTopicModeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPCHVqQDIbX5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install GetoldTweets3\n",
        "!pip install spacy\n",
        "!pip install pyLDAvis"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvuIVzZaIhQx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import GetOldTweets3 as got\n",
        "import re\n",
        "import string\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import datetime\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0Nu1sukXquE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pprint import pprint\n",
        "import gensim\n",
        "import gensim.corpora as corpora\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.models import CoherenceModel\n",
        "import spacy\n",
        "import pyLDAvis\n",
        "import pyLDAvis.gensim\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import logging\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVr1QPaCKkW5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#To import the users tweeets into a CSV file\n",
        "import csv\n",
        "with open('/content/ArvindBhatt.csv', 'a') as csvFile:\n",
        "  fieldnames = ['Tweets', 'Username', 'Date', 'Hashtags']\n",
        "  writer = csv.DictWriter(csvFile, fieldnames=fieldnames)\n",
        "  writer.writeheader()\n",
        "  # outF = open(\"/content/tweets_FromUsers.csv\", \"a\")\n",
        "  for i in tweet:\n",
        "     # write line to output file\n",
        "     writer.writerow({'Username': i.username, 'Tweets': i.text,'Date': i.formatted_date, 'Hashtags': i.hashtags })"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wK4Al6cIQGO2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk; \n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESzY-0R1RKZo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wlf_PHPMRQNw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import io\n",
        "df = pd.read_csv(io.BytesIO(uploaded['ArvindBhatt.csv']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7p8MacWFR23I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9a65DFiqXXb4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words('english')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wq0VZ76XYH5Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Adding Extra Stopwords to be removed from the dataset\n",
        "stop_words.extend(['http', 'https', 'twitter', 'www', 'instagram', 'com'])\n",
        "stop_words.extend(['make','say','go','bit','know','look','need','want','much','with','even','give','day','come','many','thing','well'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEyn-g7kd93V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Remove Emails\n",
        "df['Tweets'] = [re.sub('\\S*@\\S*\\s?', '', sent) for sent in df['Tweets']]\n",
        "# Remove new line characters\n",
        "df['Tweets'] = [re.sub('\\s+', ' ', sent) for sent in df['Tweets']]\n",
        "# Remove distracting single quotes\n",
        "df['Tweets'] = [re.sub(\"\\'\", \"\", sent) for sent in df['Tweets']]\n",
        "#Remove consecutive characters\n",
        "df['Tweets'] = np.vectorize(remove_pattern)(df['Tweets'], \"@[\\w]*\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLNuSLlTeZZz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sent_to_words(sentences):\n",
        "    for sentence in sentences:\n",
        "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLJd8FO4ZTZ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_pattern(input_txt, pattern):\n",
        "    r = re.findall(pattern, input_txt)\n",
        "    for i in r:\n",
        "        input_txt = re.sub(i, '', input_txt)\n",
        "        \n",
        "    return input_txt  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kky_o4LnZrcB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_stopwords(text):\n",
        "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in text]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sfe7KIk5jo5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_to_string(df):\n",
        "  for row in range(len(df)):\n",
        "    df.iloc[row].Tweets = ' '.join([str(element) for element in df.iloc[row].Tweets])\n",
        "  return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TN77nOjwIqKX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
        "    texts_out = []\n",
        "    for sent in texts:\n",
        "        doc = nlp(\" \".join(sent)) \n",
        "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
        "    return texts_out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrQQ8CHseZck",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['Tweets'] = list(sent_to_words(df['Tweets']))\n",
        "df['Tweets'] = remove_stopwords(df['Tweets'])\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cYKQrvfI84U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
        "df['Tweets'] = lemmatization(df['Tweets'], allowed_postags=['NOUN','ADJ','VERB','ADV'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0ARNw8QMs2b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['Tweets'] = remove_stopwords(df['Tweets'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOwz5jsDDcjx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = convert_to_string(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ld5j1tV30ou6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.drop([0], axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwCd5aLSbBCl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zA6JxCo0EQik",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words = ' '.join([text for text in df['Tweets']])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bw02FvqnYSN3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "th452RzwYquk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110).generate(words)\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZycnBRpkhuE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function to collect hashtags\n",
        "def hashtag_extract(df):\n",
        "    hashtags = df.loc[df['Hashtags'].notnull() , ['Hashtags']]\n",
        "    hashtags = hashtags['Hashtags'].tolist()\n",
        "    hashtags = extract_hashtags_seperate(tweet_hashtags)\n",
        "    return hashtags"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7jq2P3iv52U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_hashtags_seperate(x):\n",
        "  aList = []\n",
        "  for i in x:\n",
        "    ht = re.findall(r\"#(\\w+)\", i)\n",
        "    aList.append(ht)\n",
        "  return aList"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xi_2mnCnORs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tweet_hashtags = hashtag_extract(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jagw6n7dwr9F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tweet_hashtags = sum(tweet_hashtags, [])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nz-dPmR4lmpS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(tweet_hashtags)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fCOwKMFn7rS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tags = nltk.FreqDist(tweet_hashtags)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAmJ2pKCo8Ph",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "htags_data = pd.DataFrame({'Hashtag': list(tags.keys()),\n",
        "                  'Count': list(tags.values())})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LR2TZWSfo8VO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "htags_data.sort_values(by=['Count'], ascending=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYzy1FeRxK9r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n08Au-qYlD-Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# selecting top 10 most frequent hashtags     \n",
        "htags = htags_data.nlargest(columns=\"Count\", n = 22) \n",
        "plt.figure(figsize=(26,5))\n",
        "ax = sns.barplot(data=htags, x= \"Hashtag\", y = \"Count\")\n",
        "ax.set(ylabel = 'Count')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8mLuoNdPwM6",
        "colab_type": "text"
      },
      "source": [
        "**LDA Topic Modeling**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9E7KExKsYbgo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['Tweets'] = list(sent_to_words(df['Tweets']))\n",
        "df['Tweets'] = remove_stopwords(df['Tweets'])\n",
        "df['Tweets'] = lemmatization(df['Tweets'], allowed_postags=['NOUN','ADJ','VERB','ADV'])\n",
        "df['Tweets'] = remove_stopwords(df['Tweets'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHBRE1J8Pvdz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_lemmatized = df['Tweets']\n",
        "id2word = corpora.Dictionary(data_lemmatized)\n",
        "\n",
        "# Create Corpus\n",
        "texts = data_lemmatized\n",
        "\n",
        "# Term Document Frequency\n",
        "corpus = [id2word.doc2bow(text) for text in texts]\n",
        "\n",
        "# View\n",
        "print(corpus[:1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBqj3WV5Ri5N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(data_lemmatized)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHdLx2ZKPvgQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "[[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WEacl71RLlC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build LDA model\n",
        "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
        "                                           id2word=id2word,\n",
        "                                           num_topics=7, \n",
        "                                           random_state=100,\n",
        "                                           update_every=1,\n",
        "                                           chunksize=100,\n",
        "                                           passes=10,\n",
        "                                           alpha='auto',\n",
        "                                           per_word_topics=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Otoum71aRbDx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pprint(lda_model.print_topics())\n",
        "doc_lda = lda_model[corpus]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wxTXX-_hLbk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from corextopic import corextopic as ct"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}